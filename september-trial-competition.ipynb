{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Thsi notebook will first serve as a baseline LightGBM run, which I will type by hand - based on \"LightGBM Starter\" by firefliesqn. Once I've established this sort of baseline, I'll branch out on my own and experiment with some additional FE and maybe some other models. This notebook will probably NOT include any NN; I might come back to this later. ","metadata":{}},{"cell_type":"markdown","source":"I would ideally fork the notebook, but I would like to practice by typing out all the code myself.","metadata":{}},{"cell_type":"code","source":"#The initial dependencies; will be updated if needed\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datatable as dt\nimport optuna\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.preprocessing import RobustScaler #I'll look into other scaling methods in the future versions\nfrom sklearn.metrics import roc_auc_score\n\nimport lightgbm as lgb\n\nimport warnings\nwarnings.simplefilter('ignore')\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-30T18:23:35.288797Z","iopub.execute_input":"2021-09-30T18:23:35.289583Z","iopub.status.idle":"2021-09-30T18:23:35.304065Z","shell.execute_reply.started":"2021-09-30T18:23:35.289546Z","shell.execute_reply":"2021-09-30T18:23:35.303218Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-sep-2021/train.csv\n/kaggle/input/tabular-playground-series-sep-2021/test.csv\n/kaggle/input/tabular-playground-series-sep-2021/sample_solution.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = dt.fread('/kaggle/input/tabular-playground-series-sep-2021/train.csv').to_pandas()\ntest_df = dt.fread('/kaggle/input/tabular-playground-series-sep-2021/test.csv').to_pandas()\nsample_df = dt.fread('/kaggle/input/tabular-playground-series-sep-2021/sample_solution.csv').to_pandas()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:13:41.105741Z","iopub.execute_input":"2021-09-30T18:13:41.106074Z","iopub.status.idle":"2021-09-30T18:13:57.604505Z","shell.execute_reply.started":"2021-09-30T18:13:41.106033Z","shell.execute_reply":"2021-09-30T18:13:57.603844Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Datasets imported, let's now check the shape of those datasets:","metadata":{}},{"cell_type":"code","source":"print(f'Shape of train_df: {train_df.shape}')\nprint(f'Shape of test_df: {test_df.shape}')\nprint(f'Shape of sample_df: {sample_df.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:13:57.605666Z","iopub.execute_input":"2021-09-30T18:13:57.606130Z","iopub.status.idle":"2021-09-30T18:13:57.613422Z","shell.execute_reply.started":"2021-09-30T18:13:57.606090Z","shell.execute_reply":"2021-09-30T18:13:57.612533Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Shape of train_df: (957919, 120)\nShape of test_df: (493474, 119)\nShape of sample_df: (493474, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:13:57.615121Z","iopub.execute_input":"2021-09-30T18:13:57.616098Z","iopub.status.idle":"2021-09-30T18:13:57.670863Z","shell.execute_reply.started":"2021-09-30T18:13:57.616057Z","shell.execute_reply":"2021-09-30T18:13:57.670169Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   id       f1        f2         f3        f4       f5        f6       f7  \\\n0   0  0.10859  0.004314    -37.566  0.017364  0.28915 -10.25100   135.12   \n1   1  0.10090  0.299610  11822.000  0.276500  0.45970  -0.83733  1721.90   \n2   2  0.17803 -0.006980    907.270  0.272140  0.45948   0.17327  2298.00   \n3   3  0.15236  0.007259    780.100  0.025179  0.51947   7.49140   112.51   \n4   4  0.11623  0.502900   -109.150  0.297910  0.34490  -0.40932  2538.90   \n\n         f8            f9  ...     f110    f111     f112      f113      f114  \\\n0  168900.0  3.992400e+14  ... -12.2280  1.7482  1.90960  -7.11570   4378.80   \n1  119810.0  3.874100e+15  ... -56.7580  4.1684  0.34808   4.14200    913.23   \n2  360650.0  1.224500e+13  ...  -5.7688  1.2042  0.26290   8.13120  45119.00   \n3  259490.0  7.781400e+13  ... -34.8580  2.0694  0.79631 -16.33600   4952.40   \n4   65332.0  1.907200e+15  ... -13.6410  1.5298  1.14640  -0.43124   3856.50   \n\n     f115          f116    f117     f118  claim  \n0  1.2096  8.613400e+14   140.1  1.01770   True  \n1  1.2464  7.575100e+15  1861.0  0.28359  False  \n2  1.1764  3.218100e+14  3838.2  0.40690   True  \n3  1.1784  4.533000e+12  4889.1  0.51486   True  \n4  1.4830 -8.991300e+12     NaN  0.23049   True  \n\n[5 rows x 120 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>f6</th>\n      <th>f7</th>\n      <th>f8</th>\n      <th>f9</th>\n      <th>...</th>\n      <th>f110</th>\n      <th>f111</th>\n      <th>f112</th>\n      <th>f113</th>\n      <th>f114</th>\n      <th>f115</th>\n      <th>f116</th>\n      <th>f117</th>\n      <th>f118</th>\n      <th>claim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.10859</td>\n      <td>0.004314</td>\n      <td>-37.566</td>\n      <td>0.017364</td>\n      <td>0.28915</td>\n      <td>-10.25100</td>\n      <td>135.12</td>\n      <td>168900.0</td>\n      <td>3.992400e+14</td>\n      <td>...</td>\n      <td>-12.2280</td>\n      <td>1.7482</td>\n      <td>1.90960</td>\n      <td>-7.11570</td>\n      <td>4378.80</td>\n      <td>1.2096</td>\n      <td>8.613400e+14</td>\n      <td>140.1</td>\n      <td>1.01770</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.10090</td>\n      <td>0.299610</td>\n      <td>11822.000</td>\n      <td>0.276500</td>\n      <td>0.45970</td>\n      <td>-0.83733</td>\n      <td>1721.90</td>\n      <td>119810.0</td>\n      <td>3.874100e+15</td>\n      <td>...</td>\n      <td>-56.7580</td>\n      <td>4.1684</td>\n      <td>0.34808</td>\n      <td>4.14200</td>\n      <td>913.23</td>\n      <td>1.2464</td>\n      <td>7.575100e+15</td>\n      <td>1861.0</td>\n      <td>0.28359</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.17803</td>\n      <td>-0.006980</td>\n      <td>907.270</td>\n      <td>0.272140</td>\n      <td>0.45948</td>\n      <td>0.17327</td>\n      <td>2298.00</td>\n      <td>360650.0</td>\n      <td>1.224500e+13</td>\n      <td>...</td>\n      <td>-5.7688</td>\n      <td>1.2042</td>\n      <td>0.26290</td>\n      <td>8.13120</td>\n      <td>45119.00</td>\n      <td>1.1764</td>\n      <td>3.218100e+14</td>\n      <td>3838.2</td>\n      <td>0.40690</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.15236</td>\n      <td>0.007259</td>\n      <td>780.100</td>\n      <td>0.025179</td>\n      <td>0.51947</td>\n      <td>7.49140</td>\n      <td>112.51</td>\n      <td>259490.0</td>\n      <td>7.781400e+13</td>\n      <td>...</td>\n      <td>-34.8580</td>\n      <td>2.0694</td>\n      <td>0.79631</td>\n      <td>-16.33600</td>\n      <td>4952.40</td>\n      <td>1.1784</td>\n      <td>4.533000e+12</td>\n      <td>4889.1</td>\n      <td>0.51486</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.11623</td>\n      <td>0.502900</td>\n      <td>-109.150</td>\n      <td>0.297910</td>\n      <td>0.34490</td>\n      <td>-0.40932</td>\n      <td>2538.90</td>\n      <td>65332.0</td>\n      <td>1.907200e+15</td>\n      <td>...</td>\n      <td>-13.6410</td>\n      <td>1.5298</td>\n      <td>1.14640</td>\n      <td>-0.43124</td>\n      <td>3856.50</td>\n      <td>1.4830</td>\n      <td>-8.991300e+12</td>\n      <td>NaN</td>\n      <td>0.23049</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 120 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we can split the datasets into the appropriate Xs and ys:","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:19:12.897534Z","iopub.execute_input":"2021-09-15T18:19:12.898942Z","iopub.status.idle":"2021-09-15T18:19:12.906029Z","shell.execute_reply.started":"2021-09-15T18:19:12.898881Z","shell.execute_reply":"2021-09-15T18:19:12.905076Z"}}},{"cell_type":"code","source":"X_train = train_df.drop(['id', 'claim'], axis=1)\ny_train = train_df['claim'].copy()\n\nX_test = test_df.drop('id', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:13:57.673806Z","iopub.execute_input":"2021-09-30T18:13:57.674164Z","iopub.status.idle":"2021-09-30T18:13:58.056511Z","shell.execute_reply.started":"2021-09-30T18:13:57.674122Z","shell.execute_reply":"2021-09-30T18:13:58.055412Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Soo... Browsing through the discussions, I've learned that a big lesson to be learned from this dataset is that the missing values are not put there at random. Or, put another way, it is a feature itself which may help establish if there was a claim or not. Well, let's add this feature as well as the standard deviation to our dataset to help us make a better prediction:","metadata":{}},{"cell_type":"code","source":"for column in X_train.columns:\n    print(f'{column}: {X_train[column].isna().sum()}')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:13:58.058269Z","iopub.execute_input":"2021-09-30T18:13:58.058831Z","iopub.status.idle":"2021-09-30T18:13:58.341178Z","shell.execute_reply.started":"2021-09-30T18:13:58.058786Z","shell.execute_reply":"2021-09-30T18:13:58.340387Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"f1: 15247\nf2: 15190\nf3: 15491\nf4: 15560\nf5: 15405\nf6: 15521\nf7: 15504\nf8: 15373\nf9: 15249\nf10: 15223\nf11: 15425\nf12: 15593\nf13: 15464\nf14: 15222\nf15: 15509\nf16: 15444\nf17: 15427\nf18: 15325\nf19: 15474\nf20: 15455\nf21: 15454\nf22: 15278\nf23: 15356\nf24: 15630\nf25: 15506\nf26: 15358\nf27: 15444\nf28: 15265\nf29: 15415\nf30: 15392\nf31: 15678\nf32: 15529\nf33: 15492\nf34: 15248\nf35: 15334\nf36: 15363\nf37: 15312\nf38: 15434\nf39: 15559\nf40: 15368\nf41: 15396\nf42: 15416\nf43: 15455\nf44: 15463\nf45: 15483\nf46: 15633\nf47: 15523\nf48: 15446\nf49: 15380\nf50: 15562\nf51: 15432\nf52: 15315\nf53: 15462\nf54: 15425\nf55: 15422\nf56: 15467\nf57: 15573\nf58: 15455\nf59: 15400\nf60: 15560\nf61: 15431\nf62: 15518\nf63: 15410\nf64: 15578\nf65: 15414\nf66: 15414\nf67: 15486\nf68: 15619\nf69: 15552\nf70: 15262\nf71: 15482\nf72: 15219\nf73: 15537\nf74: 15570\nf75: 15456\nf76: 15569\nf77: 15251\nf78: 15449\nf79: 15378\nf80: 15320\nf81: 15346\nf82: 15485\nf83: 15627\nf84: 15385\nf85: 15449\nf86: 15523\nf87: 15316\nf88: 15548\nf89: 15445\nf90: 15482\nf91: 15507\nf92: 15492\nf93: 15457\nf94: 15414\nf95: 15599\nf96: 15285\nf97: 15265\nf98: 15288\nf99: 15434\nf100: 15526\nf101: 15349\nf102: 15168\nf103: 15600\nf104: 15198\nf105: 15386\nf106: 15544\nf107: 15384\nf108: 15340\nf109: 15529\nf110: 15365\nf111: 15499\nf112: 15410\nf113: 15233\nf114: 15438\nf115: 15559\nf116: 15589\nf117: 15407\nf118: 15212\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Approximately 15k out of nearly 1M rows; I think it's safe to impute these values with the median value and not affect the data too severely, but at least get rid of the NaNs","metadata":{}},{"cell_type":"code","source":"X_train['n_miss'] = X_train.isna().sum(axis=1)\nX_test['n_miss'] = X_test.isna().sum(axis=1)\n\n#Now I realize why there was a list of columns, if we compute the standard deviation as is, 'n_miss' will be also taken into account\n#I'll stick to using a slice of the dataframe:\nX_train['std'] = X_train[:-1].std(axis=1)\nX_test['std'] = X_test[:-1].std(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:13:58.343160Z","iopub.execute_input":"2021-09-30T18:13:58.343377Z","iopub.status.idle":"2021-09-30T18:14:00.212840Z","shell.execute_reply.started":"2021-09-30T18:13:58.343352Z","shell.execute_reply":"2021-09-30T18:14:00.212038Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:00.214213Z","iopub.execute_input":"2021-09-30T18:14:00.215122Z","iopub.status.idle":"2021-09-30T18:14:00.256253Z","shell.execute_reply.started":"2021-09-30T18:14:00.215081Z","shell.execute_reply":"2021-09-30T18:14:00.255412Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"        f1        f2         f3        f4       f5        f6       f7  \\\n0  0.10859  0.004314    -37.566  0.017364  0.28915 -10.25100   135.12   \n1  0.10090  0.299610  11822.000  0.276500  0.45970  -0.83733  1721.90   \n2  0.17803 -0.006980    907.270  0.272140  0.45948   0.17327  2298.00   \n3  0.15236  0.007259    780.100  0.025179  0.51947   7.49140   112.51   \n4  0.11623  0.502900   -109.150  0.297910  0.34490  -0.40932  2538.90   \n\n         f8            f9        f10  ...    f111     f112      f113  \\\n0  168900.0  3.992400e+14     86.489  ...  1.7482  1.90960  -7.11570   \n1  119810.0  3.874100e+15   9953.600  ...  4.1684  0.34808   4.14200   \n2  360650.0  1.224500e+13  15827.000  ...  1.2042  0.26290   8.13120   \n3  259490.0  7.781400e+13    -36.837  ...  2.0694  0.79631 -16.33600   \n4   65332.0  1.907200e+15    144.120  ...  1.5298  1.14640  -0.43124   \n\n       f114    f115          f116    f117     f118  n_miss           std  \n0   4378.80  1.2096  8.613400e+14   140.1  1.01770       1  1.008624e+15  \n1    913.23  1.2464  7.575100e+15  1861.0  0.28359       0  2.933337e+15  \n2  45119.00  1.1764  3.218100e+14  3838.2  0.40690       5  3.092107e+13  \n3   4952.40  1.1784  4.533000e+12  4889.1  0.51486       2  1.755542e+14  \n4   3856.50  1.4830 -8.991300e+12     NaN  0.23049       8  9.771993e+14  \n\n[5 rows x 120 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>f6</th>\n      <th>f7</th>\n      <th>f8</th>\n      <th>f9</th>\n      <th>f10</th>\n      <th>...</th>\n      <th>f111</th>\n      <th>f112</th>\n      <th>f113</th>\n      <th>f114</th>\n      <th>f115</th>\n      <th>f116</th>\n      <th>f117</th>\n      <th>f118</th>\n      <th>n_miss</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.10859</td>\n      <td>0.004314</td>\n      <td>-37.566</td>\n      <td>0.017364</td>\n      <td>0.28915</td>\n      <td>-10.25100</td>\n      <td>135.12</td>\n      <td>168900.0</td>\n      <td>3.992400e+14</td>\n      <td>86.489</td>\n      <td>...</td>\n      <td>1.7482</td>\n      <td>1.90960</td>\n      <td>-7.11570</td>\n      <td>4378.80</td>\n      <td>1.2096</td>\n      <td>8.613400e+14</td>\n      <td>140.1</td>\n      <td>1.01770</td>\n      <td>1</td>\n      <td>1.008624e+15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.10090</td>\n      <td>0.299610</td>\n      <td>11822.000</td>\n      <td>0.276500</td>\n      <td>0.45970</td>\n      <td>-0.83733</td>\n      <td>1721.90</td>\n      <td>119810.0</td>\n      <td>3.874100e+15</td>\n      <td>9953.600</td>\n      <td>...</td>\n      <td>4.1684</td>\n      <td>0.34808</td>\n      <td>4.14200</td>\n      <td>913.23</td>\n      <td>1.2464</td>\n      <td>7.575100e+15</td>\n      <td>1861.0</td>\n      <td>0.28359</td>\n      <td>0</td>\n      <td>2.933337e+15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.17803</td>\n      <td>-0.006980</td>\n      <td>907.270</td>\n      <td>0.272140</td>\n      <td>0.45948</td>\n      <td>0.17327</td>\n      <td>2298.00</td>\n      <td>360650.0</td>\n      <td>1.224500e+13</td>\n      <td>15827.000</td>\n      <td>...</td>\n      <td>1.2042</td>\n      <td>0.26290</td>\n      <td>8.13120</td>\n      <td>45119.00</td>\n      <td>1.1764</td>\n      <td>3.218100e+14</td>\n      <td>3838.2</td>\n      <td>0.40690</td>\n      <td>5</td>\n      <td>3.092107e+13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.15236</td>\n      <td>0.007259</td>\n      <td>780.100</td>\n      <td>0.025179</td>\n      <td>0.51947</td>\n      <td>7.49140</td>\n      <td>112.51</td>\n      <td>259490.0</td>\n      <td>7.781400e+13</td>\n      <td>-36.837</td>\n      <td>...</td>\n      <td>2.0694</td>\n      <td>0.79631</td>\n      <td>-16.33600</td>\n      <td>4952.40</td>\n      <td>1.1784</td>\n      <td>4.533000e+12</td>\n      <td>4889.1</td>\n      <td>0.51486</td>\n      <td>2</td>\n      <td>1.755542e+14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.11623</td>\n      <td>0.502900</td>\n      <td>-109.150</td>\n      <td>0.297910</td>\n      <td>0.34490</td>\n      <td>-0.40932</td>\n      <td>2538.90</td>\n      <td>65332.0</td>\n      <td>1.907200e+15</td>\n      <td>144.120</td>\n      <td>...</td>\n      <td>1.5298</td>\n      <td>1.14640</td>\n      <td>-0.43124</td>\n      <td>3856.50</td>\n      <td>1.4830</td>\n      <td>-8.991300e+12</td>\n      <td>NaN</td>\n      <td>0.23049</td>\n      <td>8</td>\n      <td>9.771993e+14</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 120 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Now in the original author's notebook, the NaN's were imputed with mean values, but I would like to stick to median values:\nX_train = X_train.fillna(X_train.median())\nX_test = X_test.fillna(X_test.median())\n\nprint(f'NaNs in X_train: {X_train.isna().sum().sum()}')\nprint(f'NaNs in X_test: {X_test.isna().sum().sum()}')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:00.257645Z","iopub.execute_input":"2021-09-30T18:14:00.258070Z","iopub.status.idle":"2021-09-30T18:14:04.801979Z","shell.execute_reply.started":"2021-09-30T18:14:00.258026Z","shell.execute_reply":"2021-09-30T18:14:04.801115Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"NaNs in X_train: 0\nNaNs in X_test: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Great! Now that the missing values have been taken care of, we can handle some scaling efforts:","metadata":{}},{"cell_type":"code","source":"scaler = RobustScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:04.803455Z","iopub.execute_input":"2021-09-30T18:14:04.803911Z","iopub.status.idle":"2021-09-30T18:14:12.890397Z","shell.execute_reply.started":"2021-09-30T18:14:04.803872Z","shell.execute_reply":"2021-09-30T18:14:12.889543Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"'''A function to reduce the amount of memory taken up by each feature by compressing it to the appropriate datatype\nverbose parameter is used to output a message regarding the exact memory usage reduction'''\ndef reduce_memory_usage(df, verbose=True):\n    numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024 ** 2 #initial memory usage to compare to\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            #extract the min and max values\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                else:\n                #elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024 ** 2 #new memory_usage\n    if verbose:\n        print(\n            \"Memory usage decreased to: {:.2f} Mb - {:.1f}% reduction\".format(\n                end_mem, 100 * (start_mem - end_mem) / start_mem\n                \n                )\n            )\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:12.891797Z","iopub.execute_input":"2021-09-30T18:14:12.892318Z","iopub.status.idle":"2021-09-30T18:14:12.908020Z","shell.execute_reply.started":"2021-09-30T18:14:12.892278Z","shell.execute_reply":"2021-09-30T18:14:12.907135Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_train = pd.DataFrame(X_train)\nX_test = pd.DataFrame(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:12.911056Z","iopub.execute_input":"2021-09-30T18:14:12.911278Z","iopub.status.idle":"2021-09-30T18:14:12.922406Z","shell.execute_reply.started":"2021-09-30T18:14:12.911253Z","shell.execute_reply":"2021-09-30T18:14:12.921499Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(\"X_train redution:\")\nX_train = reduce_memory_usage(X_train)\nprint(\"X_test reduction:\")\nX_test = reduce_memory_usage(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:12.923905Z","iopub.execute_input":"2021-09-30T18:14:12.924262Z","iopub.status.idle":"2021-09-30T18:14:38.962723Z","shell.execute_reply.started":"2021-09-30T18:14:12.924222Z","shell.execute_reply":"2021-09-30T18:14:38.961899Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"X_train redution:\nMemory usage decreased to: 219.25 Mb - 75.0% reduction\nX_test reduction:\nMemory usage decreased to: 112.95 Mb - 75.0% reduction\n","output_type":"stream"}]},{"cell_type":"code","source":"#X_train_df = pd.DataFrame(X_train)\n#X_train_df.hist(bins=50, figsize=(20,15))\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:38.965568Z","iopub.execute_input":"2021-09-30T18:14:38.966396Z","iopub.status.idle":"2021-09-30T18:14:38.970410Z","shell.execute_reply.started":"2021-09-30T18:14:38.966355Z","shell.execute_reply":"2021-09-30T18:14:38.969624Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Lots of different distributions, some normal, some bi- or multimodal; tough luck... Probably the best solution would be to apply a transformation across the board.\n","metadata":{}},{"cell_type":"markdown","source":"Below are some initial params of the LightGBM algorhithm; I'll write them down for now. But probably I'll extend them to be lists of hyperparameters to tune:","metadata":{}},{"cell_type":"markdown","source":"The initial n_estimators did not result in early stopping, so it's probably wise to continue with the estimators - Early stopping will help us achieve this goal","metadata":{}},{"cell_type":"code","source":"x_tra, x_val, y_tra, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:38.971527Z","iopub.execute_input":"2021-09-30T18:14:38.971880Z","iopub.status.idle":"2021-09-30T18:14:39.974400Z","shell.execute_reply.started":"2021-09-30T18:14:38.971839Z","shell.execute_reply":"2021-09-30T18:14:39.973380Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    num_leaves = trial.suggest_int(\"num_leaves\", 20, 40)\n    n_estimators = trial.suggest_int(\"n_estimators\", 500, 2000)\n    max_depth = trial.suggest_int('max_depth', 3, 8)\n    min_child_samples = trial.suggest_int('min_child_samples', 200, 750)\n    learning_rate = trial.suggest_uniform('learning_rate', 0.10, 0.30)\n    bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.50, 1.0)\n    colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.50, 1.0)\n    \n    model = lgb.LGBMClassifier(\n        objective='binary',\n        metric='auc',\n        num_leaves=num_leaves,\n        n_estimators=n_estimators, \n        max_depth=max_depth, \n        min_child_samples=min_child_samples, \n        learning_rate=learning_rate,\n        colsample_bytree=colsample_bytree,\n        random_state=42,\n    )\n    \n    model.fit(x_tra, y_tra)\n    #see link in markdown above for this next line\n    score = roc_auc_score(y_val, model.predict_proba(x_val)[:,1])\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:50:28.477912Z","iopub.execute_input":"2021-09-30T18:50:28.478562Z","iopub.status.idle":"2021-09-30T18:50:28.486304Z","shell.execute_reply.started":"2021-09-30T18:50:28.478524Z","shell.execute_reply":"2021-09-30T18:50:28.485632Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=10)\nparams = study.best_params #getting best params from study","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:50:31.911396Z","iopub.execute_input":"2021-09-30T18:50:31.911651Z","iopub.status.idle":"2021-09-30T19:33:43.662708Z","shell.execute_reply.started":"2021-09-30T18:50:31.911624Z","shell.execute_reply":"2021-09-30T19:33:43.662002Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2021-09-30 18:50:31,913]\u001b[0m A new study created in memory with name: no-name-7d57ea69-beb5-46b7-a29c-87980b0f3fef\u001b[0m\n\u001b[32m[I 2021-09-30 18:55:04,911]\u001b[0m Trial 0 finished with value: 0.8014599383458805 and parameters: {'num_leaves': 33, 'n_estimators': 1512, 'max_depth': 8, 'min_child_samples': 549, 'learning_rate': 0.27673148003635156, 'bagging_fraction': 0.6906505015910112, 'colsample_bytree': 0.593482370921205}. Best is trial 0 with value: 0.8014599383458805.\u001b[0m\n\u001b[32m[I 2021-09-30 18:59:10,705]\u001b[0m Trial 1 finished with value: 0.8140771976000376 and parameters: {'num_leaves': 32, 'n_estimators': 1418, 'max_depth': 3, 'min_child_samples': 729, 'learning_rate': 0.1524242132456086, 'bagging_fraction': 0.8207267301624811, 'colsample_bytree': 0.7754814041080009}. Best is trial 1 with value: 0.8140771976000376.\u001b[0m\n\u001b[32m[I 2021-09-30 19:03:17,183]\u001b[0m Trial 2 finished with value: 0.8082687435976919 and parameters: {'num_leaves': 23, 'n_estimators': 1116, 'max_depth': 7, 'min_child_samples': 219, 'learning_rate': 0.2076242506665712, 'bagging_fraction': 0.9555735869440053, 'colsample_bytree': 0.8787519203751937}. Best is trial 1 with value: 0.8140771976000376.\u001b[0m\n\u001b[32m[I 2021-09-30 19:05:06,101]\u001b[0m Trial 3 finished with value: 0.813867925278199 and parameters: {'num_leaves': 29, 'n_estimators': 778, 'max_depth': 3, 'min_child_samples': 716, 'learning_rate': 0.1621444573323083, 'bagging_fraction': 0.9406056581458939, 'colsample_bytree': 0.5603569824855874}. Best is trial 1 with value: 0.8140771976000376.\u001b[0m\n\u001b[32m[I 2021-09-30 19:08:28,932]\u001b[0m Trial 4 finished with value: 0.8142675014783982 and parameters: {'num_leaves': 32, 'n_estimators': 1432, 'max_depth': 3, 'min_child_samples': 677, 'learning_rate': 0.13756022304101814, 'bagging_fraction': 0.5245456029759956, 'colsample_bytree': 0.5834374379486099}. Best is trial 4 with value: 0.8142675014783982.\u001b[0m\n\u001b[32m[I 2021-09-30 19:12:52,995]\u001b[0m Trial 5 finished with value: 0.811461861364008 and parameters: {'num_leaves': 29, 'n_estimators': 1159, 'max_depth': 5, 'min_child_samples': 456, 'learning_rate': 0.14694935340226611, 'bagging_fraction': 0.7111148114045965, 'colsample_bytree': 0.7126009243666311}. Best is trial 4 with value: 0.8142675014783982.\u001b[0m\n\u001b[32m[I 2021-09-30 19:16:38,283]\u001b[0m Trial 6 finished with value: 0.8106680565140997 and parameters: {'num_leaves': 34, 'n_estimators': 935, 'max_depth': 4, 'min_child_samples': 242, 'learning_rate': 0.2620121305061347, 'bagging_fraction': 0.522620958898328, 'colsample_bytree': 0.9255920487566371}. Best is trial 4 with value: 0.8142675014783982.\u001b[0m\n\u001b[32m[I 2021-09-30 19:22:09,741]\u001b[0m Trial 7 finished with value: 0.8139073184678555 and parameters: {'num_leaves': 24, 'n_estimators': 1690, 'max_depth': 4, 'min_child_samples': 525, 'learning_rate': 0.1019553418253063, 'bagging_fraction': 0.8028792177307089, 'colsample_bytree': 0.7329568514073506}. Best is trial 4 with value: 0.8142675014783982.\u001b[0m\n\u001b[32m[I 2021-09-30 19:29:29,342]\u001b[0m Trial 8 finished with value: 0.8027839070170601 and parameters: {'num_leaves': 40, 'n_estimators': 1474, 'max_depth': 7, 'min_child_samples': 285, 'learning_rate': 0.2409481980329469, 'bagging_fraction': 0.8686068386600264, 'colsample_bytree': 0.9896448236810862}. Best is trial 4 with value: 0.8142675014783982.\u001b[0m\n\u001b[32m[I 2021-09-30 19:33:43,659]\u001b[0m Trial 9 finished with value: 0.8121439685705627 and parameters: {'num_leaves': 20, 'n_estimators': 1101, 'max_depth': 4, 'min_child_samples': 680, 'learning_rate': 0.19469148130342556, 'bagging_fraction': 0.6595058660713686, 'colsample_bytree': 0.8719188906768109}. Best is trial 4 with value: 0.8142675014783982.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"lgb_params = {\n    'objective': 'binary',\n    'n_estimators': 20000, #worth tuning\n    'random_state': 42,\n    'learning_rate': 4e-3, #worth tuning\n    'subsample': 0.6,\n    'subsample_freq': 1,\n    'colsample_bytree': 0.4,\n    'reg_alpha': 12.0,\n    'reg_lambda': 1e-1,\n    'min_child_weight': 256,\n    'min_child_samples': 20,\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-19T08:55:14.149799Z","iopub.execute_input":"2021-09-19T08:55:14.150474Z","iopub.status.idle":"2021-09-19T08:55:14.155012Z","shell.execute_reply.started":"2021-09-19T08:55:14.15044Z","shell.execute_reply":"2021-09-19T08:55:14.153997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lowercase and shortened to distinguish from the 'original' train sets\n#x_tra, x_val, y_tra, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True, random_state=42)\n\nlgb_classifier = lgb.LGBMClassifier(**params)\n\nlgb_classifier.fit(x_tra, y_tra, eval_set=[(x_val, y_val)],\n                  eval_metric='auc', early_stopping_rounds=200,\n                  verbose=500,\n                  )\ny_pred = lgb_classifier.predict_proba(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T19:35:06.506495Z","iopub.execute_input":"2021-09-30T19:35:06.506764Z","iopub.status.idle":"2021-09-30T19:38:56.974734Z","shell.execute_reply.started":"2021-09-30T19:35:06.506736Z","shell.execute_reply":"2021-09-30T19:38:56.974140Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] bagging_fraction is set=0.5245456029759956, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5245456029759956\nTraining until validation scores don't improve for 200 rounds\n[500]\tvalid_0's auc: 0.813253\tvalid_0's binary_logloss: 0.509945\n[1000]\tvalid_0's auc: 0.814254\tvalid_0's binary_logloss: 0.50938\nEarly stopping, best iteration is:\n[1042]\tvalid_0's auc: 0.814317\tvalid_0's binary_logloss: 0.509341\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_df['claim'] = y_pred[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-09-30T19:41:07.393935Z","iopub.execute_input":"2021-09-30T19:41:07.394712Z","iopub.status.idle":"2021-09-30T19:41:07.400671Z","shell.execute_reply.started":"2021-09-30T19:41:07.394667Z","shell.execute_reply":"2021-09-30T19:41:07.399974Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"sample_df.to_csv('submission_8.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T19:41:23.959300Z","iopub.execute_input":"2021-09-30T19:41:23.959551Z","iopub.status.idle":"2021-09-30T19:41:25.511704Z","shell.execute_reply.started":"2021-09-30T19:41:23.959525Z","shell.execute_reply":"2021-09-30T19:41:25.510985Z"},"trusted":true},"execution_count":34,"outputs":[]}]}